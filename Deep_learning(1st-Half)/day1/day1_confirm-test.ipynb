{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6758bdd-e4ad-452e-81a5-0395f635d6a6",
   "metadata": {},
   "source": [
    "### 深層学習 day1 確認テスト\n",
    "\n",
    "- #### 全体像-1\n",
    "    - DLは結局何をやろうとしているのか？\n",
    "        - 複数の隠れ層を持つニューラルネットワークを用いて、ブラックボックスな非線形モデルを構築し、利用する\n",
    "    - どの値の最適化が最終目的か？\n",
    "        - 重みとバイアス\n",
    "\n",
    "- #### 全体像-2\n",
    "    - 次のNWを書け（入力層：２ノード１層、中間層：３ノード２層、出力層：１ノード１層）\n",
    "        - \"picture_confirm-test/Overview-2.pdf\"を参照\n",
    "\n",
    "- #### Section1.入力層から中間層-1\n",
    "    - この図式（入力層、中間層(1ノード１層）が書いてあるネットワーク）に、動物分類の実例を入れてみよう\n",
    "        - 入力層に動物の分類に役立ちそうな情報を入れる（体長、体重、脊椎の有無、手足の本数、走行速度、etc…）\n",
    "        \n",
    "- #### Section1.入力層から中間層-２\n",
    "    - u = Wx + b をPythonで書け\n",
    "        - u1 = W1@x + b1\n",
    "\n",
    "- #### Section1.入力層から中間層-3\n",
    "    - 1-1のファイルから中間層の出力を定義しているソースを抜き出せ\n",
    "        - z = functions.sigmoid(u)\n",
    "        \n",
    "- #### Section２.活性化関数-1\n",
    "    - 線形と非線形の違いを図にかいて簡易に説明せよ\n",
    "        - ”picture_confirm-test/ActivationFunction-1.pdf”を参照\n",
    "        \n",
    "- #### Section２.活性化関数-2\n",
    "    - 配布されたコードより、該当する箇所を抜き出せ\n",
    "        - z = functions.sigmoid(u)\n",
    "        \n",
    "- #### Section3.出力層-1\n",
    "    - 誤差関数について。なぜ引き算でなく自乗するか述べよ\n",
    "        - 正解とのずれの大きさを見たいため。引き算だと相殺されてしまい大きさを測る方法としては適さない。絶対値でもよいが、計算上自乗の方が楽\n",
    "    - 式の1/2はどういう意味をもつか述べよ\n",
    "        - 計算を簡便にするため。\n",
    "\n",
    "- #### Section3.出力層-2\n",
    "    - ①〜③の数式に該当するソースコードを示し、一行ずつ処理の説明をせよ\n",
    "        - ① ： def softmax(x):\n",
    "        - ② ： np.exp(x)\n",
    "        - ③ ： np.sum(np.exp(x),axis=0)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b8f756ff-4988-4810-adca-d698b805972b",
   "metadata": {},
   "source": [
    "def softmax(x):\n",
    "    if x.ndim == 2: # xの次元が2のとき、以降のインデントされたブロックの処理を実施\n",
    "        x = x.T # xの転置をとる\n",
    "        x = x-np.max(x,axis=0)　# xの各要素に対して、xの最大値を減算\n",
    "        y = np.exp(x) / np.sum(np.exp(x),axis=0) # softmax出力用の変数を算出\n",
    "        return y.T # yの転置を出力\n",
    "    x = x - np.max(x)　# xの各要素に対して、xの最大値を減算\n",
    "    return np.exp(x) / np.sum(np.exp(x))　# softmax出力"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a55a3def-53c2-4d44-8405-89c8d2a6edee",
   "metadata": {},
   "source": [
    "- #### Section3.出力層-3\n",
    "    - ①〜②の数式に該当するソースコードを示し、一行ずつ処理の説明をせよ\n",
    "        - ① ： def cross_entropy_error(d,y):\n",
    "        - ② ： return -np.sum(np.log(y[np.arange(batch_size),d] + 1e-7)) / batch_size\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "44ffeb63-61fc-4237-bb75-1da51ce012bd",
   "metadata": {},
   "source": [
    "def cross_entropy_error(d, y):\n",
    "    if y.ndim == 1: # yの次元が1のとき\n",
    "        d = d.reshape(1,d.size) # 2次元(1 * size)に変換\n",
    "        y = y.reshape(1.y.size) #　　2次元(1 * size)に変換\n",
    "\n",
    "    # 教師データがOne-Hot-Vectorの場合、正解ラベルのインデックスに変換\n",
    "    if d.size == y.size:\n",
    "        d = d.argmax(axis=1)\n",
    "        \n",
    "    batch_size = y.shape[0]\n",
    "    return -np.sum(np.log(y[np.arange(batch_size), d] + 1e-7)) / batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f8f5daa-88b3-490a-94d3-dc1e32b8c1a0",
   "metadata": {},
   "source": [
    "- #### Section4.勾配降下法-1\n",
    "    - 該当するソースコードを探してみよう\n",
    "        - network[key] -= learning_rate * grad[key]\n",
    "        - grad = backward(x,d,z1,y)\n",
    "        \n",
    "- #### Section4.勾配降下法-2\n",
    "    - オンライン学習とは何か\n",
    "        - （１つの）データが与えられるたびに、そのデータを元に学習しモデルを改良すること\n",
    "        \n",
    "- #### Section4.勾配降下法-3\n",
    "    - $ w^{(t+1)} = w^{(t)} - \\epsilon \\nabla E_{t} $ の意味を図に書いて説明せよ\n",
    "        - ”picture_confirm-test/GD-3.pdf”を参照\n",
    "\n",
    "- #### Section５.誤差逆伝搬法-1\n",
    "    - 誤差逆伝搬法では不要な再帰的処理を避けることが可能。既に行った計算結果を保持しているコードを抽出せよ。\n",
    "        - delta2 = functions.d_sigmoid_with_loss(d, y)\n",
    "\n",
    "- #### Section５.誤差逆伝搬法-２\n",
    "    - 2つの空欄に該当するソースコードを探せ\n",
    "        - delta2 = functions.d_mean_squared_error(d, y)\n",
    "        - grad['W2'] = np.dot(z1.T, delta2)\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa56880-44cf-445e-b588-45b4d64416b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
